package frc.robot.subsystems;

import static edu.wpi.first.units.Units.Second;
import static edu.wpi.first.units.Units.Volts;

import java.util.Optional;
import java.util.function.Consumer;
import java.util.function.DoubleSupplier;
import java.util.function.Supplier;

import org.opencv.core.Mat;

import com.ctre.phoenix6.SignalLogger;
import com.ctre.phoenix6.Utils;
import com.ctre.phoenix6.swerve.SwerveDrivetrainConstants;
import com.ctre.phoenix6.swerve.SwerveModule;
import com.ctre.phoenix6.swerve.SwerveModuleConstants;
import com.ctre.phoenix6.swerve.SwerveRequest;

import edu.wpi.first.math.Matrix;
import edu.wpi.first.math.VecBuilder;
import edu.wpi.first.math.geometry.Pose2d;
import edu.wpi.first.math.geometry.Rotation2d;
import edu.wpi.first.math.geometry.Translation2d;
import edu.wpi.first.math.interpolation.InterpolatingDoubleTreeMap;
import edu.wpi.first.math.kinematics.ChassisSpeeds;
import edu.wpi.first.math.numbers.N1;
import edu.wpi.first.math.numbers.N3;
import edu.wpi.first.networktables.NetworkTable;
import edu.wpi.first.networktables.NetworkTableInstance;
import edu.wpi.first.networktables.StructPublisher;
import edu.wpi.first.wpilibj.DriverStation;
import edu.wpi.first.wpilibj.DriverStation.Alliance;
import edu.wpi.first.wpilibj.smartdashboard.SmartDashboard;
import edu.wpi.first.wpilibj.Notifier;
import edu.wpi.first.wpilibj.RobotController;
import edu.wpi.first.wpilibj.Timer;
import edu.wpi.first.wpilibj2.command.Command;
import edu.wpi.first.wpilibj2.command.Subsystem;
import edu.wpi.first.wpilibj2.command.sysid.SysIdRoutine;
import frc.robot.LimelightHelpers;
import frc.robot.LimelightHelpers.PoseEstimate;
import frc.robot.constants.RobotConstants;
import frc.robot.constants.TunerConstants.TunerSwerveDrivetrain;
import frc.team254.vision.FiducialObservation;
import frc.team254.vision.MegatagPoseEstimate;
import frc.team254.vision.VisionFieldPoseEstimate;
import frc.team254.vision.VisionProcessor;

/**
 * Class that extends the Phoenix 6 SwerveDrivetrain class and implements
 * Subsystem so it can easily be used in command-based projects.
 *
 * Generated by the 2026 Tuner X Swerve Project Generator
 * https://v6.docs.ctr-electronics.com/en/stable/docs/tuner/tuner-swerve/index.html
 */
public class CommandSwerveDrivetrain extends TunerSwerveDrivetrain implements Subsystem {
    private static final double kSimLoopPeriod = 0.004; // 4 ms
    private Notifier m_simNotifier = null;
    private double m_lastSimTime;

    /* Blue alliance sees forward as 0 degrees (toward red alliance wall) */
    private static final Rotation2d kBlueAlliancePerspectiveRotation = Rotation2d.kZero;
    /* Red alliance sees forward as 180 degrees (toward blue alliance wall) */
    private static final Rotation2d kRedAlliancePerspectiveRotation = Rotation2d.k180deg;
    /* Keep track if we've ever applied the operator perspective before or not */
    private boolean m_hasAppliedOperatorPerspective = false;

    private static final Pose2d blueHubPose = new Pose2d(4.626, 4.035, new Rotation2d());
    private static final Pose2d redHubPose = new Pose2d(11.914, 4.035, new Rotation2d());

    private final DoubleSupplier turretAngleSupplier;

    NetworkTable appleTable = NetworkTableInstance.getDefault().getTable("limelight-apple");

    private final NetworkTableInstance test = NetworkTableInstance.getDefault();
    
    private final NetworkTable poseStateTable = test.getTable("PoseStates");
    private final StructPublisher<Pose2d> limelightDisplacedPose = poseStateTable.getStructTopic("LimelightDisplacedPose", Pose2d.struct).publish();

    public final Consumer<VisionFieldPoseEstimate> visionEstimateConsumer = new Consumer<>() {
        @Override
        public void accept(VisionFieldPoseEstimate visionFieldPoseEstimate) {
            addVisionMeasurement(visionFieldPoseEstimate);
                 return;
        }
    };

    VisionProcessor visionProcessor = new VisionProcessor(visionEstimateConsumer);

    /* Swerve requests to apply during SysId characterization */
    private final SwerveRequest.SysIdSwerveTranslation m_translationCharacterization = new SwerveRequest.SysIdSwerveTranslation();
    private final SwerveRequest.SysIdSwerveSteerGains m_steerCharacterization = new SwerveRequest.SysIdSwerveSteerGains();
    private final SwerveRequest.SysIdSwerveRotation m_rotationCharacterization = new SwerveRequest.SysIdSwerveRotation();

    public final SwerveRequest.ApplyRobotSpeeds m_pathApplyRobotSpeeds =
            new SwerveRequest.ApplyRobotSpeeds()
                    .withDriveRequestType(SwerveModule.DriveRequestType.Velocity)
                    .withSteerRequestType(SwerveModule.SteerRequestType.Position);


    /* SysId routine for characterizing translation. This is used to find PID gains for the drive motors. */
    private final SysIdRoutine m_sysIdRoutineTranslation = new SysIdRoutine(
        new SysIdRoutine.Config(
            null,        // Use default ramp rate (1 V/s)
            Volts.of(4), // Reduce dynamic step voltage to 4 V to prevent brownout
            null,        // Use default timeout (10 s)
            // Log state with SignalLogger class
            state -> SignalLogger.writeString("SysIdTranslation_State", state.toString())
        ),
        new SysIdRoutine.Mechanism(
            output -> setControl(m_translationCharacterization.withVolts(output)),
            null,
            this
        )
    );

    /* SysId routine for characterizing steer. This is used to find PID gains for the steer motors. */
    private final SysIdRoutine m_sysIdRoutineSteer = new SysIdRoutine(
        new SysIdRoutine.Config(
            null,        // Use default ramp rate (1 V/s)
            Volts.of(7), // Use dynamic voltage of 7 V
            null,        // Use default timeout (10 s)
            // Log state with SignalLogger class
            state -> SignalLogger.writeString("SysIdSteer_State", state.toString())
        ),
        new SysIdRoutine.Mechanism(
            volts -> setControl(m_steerCharacterization.withVolts(volts)),
            null,
            this
        )
    );

    /*
     * SysId routine for characterizing rotation.
     * This is used to find PID gains for the FieldCentricFacingAngle HeadingController.
     * See the documentation of SwerveRequest.SysIdSwerveRotation for info on importing the log to SysId.
     */
    private final SysIdRoutine m_sysIdRoutineRotation = new SysIdRoutine(
        new SysIdRoutine.Config(
            /* This is in radians per second², but SysId only supports "volts per second" */
            Volts.of(Math.PI / 6).per(Second),
            /* This is in radians per second, but SysId only supports "volts" */
            Volts.of(Math.PI),
            null, // Use default timeout (10 s)
            // Log state with SignalLogger class
            state -> SignalLogger.writeString("SysIdRotation_State", state.toString())
        ),
        new SysIdRoutine.Mechanism(
            output -> {
                /* output is actually radians per second, but SysId only supports "volts" */
                setControl(m_rotationCharacterization.withRotationalRate(output.in(Volts)));
                /* also log the requested output for SysId */
                SignalLogger.writeDouble("Rotational_Rate", output.in(Volts));
            },
            null,
            this
        )
    );

    /* The SysId routine to test */
    private SysIdRoutine m_sysIdRoutineToApply = m_sysIdRoutineTranslation;

    /**
     * Constructs a CTRE SwerveDrivetrain using the specified constants.
     * <p>
     * This constructs the underlying hardware devices, so users should not construct
     * the devices themselves. If they need the devices, they can access them through
     * getters in the classes.
     *
     * @param drivetrainConstants   Drivetrain-wide constants for the swerve drive
     * @param modules               Constants for each specific module
     */
    public CommandSwerveDrivetrain(
        DoubleSupplier turretAngleSupplier,
        SwerveDrivetrainConstants drivetrainConstants,
        SwerveModuleConstants<?, ?, ?>... modules
    ) {
        super(drivetrainConstants, modules);
        if (Utils.isSimulation()) {
            startSimThread();
        }
        
        this.turretAngleSupplier = turretAngleSupplier;
    }

    /**
     * Returns a command that applies the specified control request to this swerve drivetrain.
     *
     * @param request Function returning the request to apply
     * @return Command to run
     */
    public Command applyRequest(Supplier<SwerveRequest> request) {
        return run(() -> this.setControl(request.get()));
    }

    /**
     * Runs the SysId Quasistatic test in the given direction for the routine
     * specified by {@link #m_sysIdRoutineToApply}.
     *
     * @param direction Direction of the SysId Quasistatic test
     * @return Command to run
     */
    public Command sysIdQuasistatic(SysIdRoutine.Direction direction) {
        return m_sysIdRoutineToApply.quasistatic(direction);
    }

    /**
     * Runs the SysId Dynamic test in the given direction for the routine
     * specified by {@link #m_sysIdRoutineToApply}.
     *
     * @param direction Direction of the SysId Dynamic test
     * @return Command to run
     */
    public Command sysIdDynamic(SysIdRoutine.Direction direction) {
        return m_sysIdRoutineToApply.dynamic(direction);
    }

    public void addVisionMeasurement(VisionFieldPoseEstimate visionFieldPoseEstimate) {
        if (visionFieldPoseEstimate.getVisionMeasurementStdDevs() == null) {
            super.addVisionMeasurement(
                    visionFieldPoseEstimate.getVisionRobotPoseMeters(),
                    Utils.fpgaToCurrentTime(visionFieldPoseEstimate.getTimestampSeconds())
            );
        } else {
            super.addVisionMeasurement(
                    visionFieldPoseEstimate.getVisionRobotPoseMeters(),
                    Utils.fpgaToCurrentTime(visionFieldPoseEstimate.getTimestampSeconds()),
                    visionFieldPoseEstimate.getVisionMeasurementStdDevs()
            );
        }
    }

    @Override
    public void periodic() {

        visionPeriodic();

        /*
         * Periodically try to apply the operator perspective.
         * If we haven't applied the operator perspective before, then we should apply it regardless of DS state.
         * This allows us to correct the perspective in case the robot code restarts mid-match.
         * Otherwise, only check and apply the operator perspective if the DS is disabled.
         * This ensures driving behavior doesn't change until an explicit disable event occurs during testing.
         */
        if (!m_hasAppliedOperatorPerspective || DriverStation.isDisabled()) {
            DriverStation.getAlliance().ifPresent(allianceColor -> {
                setOperatorPerspectiveForward(
                    allianceColor == Alliance.Red
                        ? kRedAlliancePerspectiveRotation
                        : kBlueAlliancePerspectiveRotation
                );
                m_hasAppliedOperatorPerspective = true;
            });
        }
    }

    private void startSimThread() {
        m_lastSimTime = Utils.getCurrentTimeSeconds();

        /* Run simulation at a faster rate so PID gains behave more reasonably */
        m_simNotifier = new Notifier(() -> {
            final double currentTime = Utils.getCurrentTimeSeconds();
            double deltaTime = currentTime - m_lastSimTime;
            m_lastSimTime = currentTime;

            /* use the measured time delta, get battery voltage from WPILib */
            updateSimState(deltaTime, RobotController.getBatteryVoltage());
        });
        m_simNotifier.startPeriodic(kSimLoopPeriod);
    }

    /**
     * Adds a vision measurement to the Kalman Filter. This will correct the odometry pose estimate
     * while still accounting for measurement noise.
     *
     * @param visionRobotPoseMeters The pose of the robot as measured by the vision camera.
     * @param timestampSeconds The timestamp of the vision measurement in seconds.
     */
    @Override
    public void addVisionMeasurement(Pose2d visionRobotPoseMeters, double timestampSeconds) {
        super.addVisionMeasurement(visionRobotPoseMeters, Utils.fpgaToCurrentTime(timestampSeconds));
    }

    /**
     * Adds a vision measurement to the Kalman Filter. This will correct the odometry pose estimate
     * while still accounting for measurement noise.
     * <p>
     * Note that the vision measurement standard deviations passed into this method
     * will continue to apply to future measurements until a subsequent call to
     * {@link #setVisionMeasurementStdDevs(Matrix)} or this method.
     *
     * @param visionRobotPoseMeters The pose of the robot as measured by the vision camera.
     * @param timestampSeconds The timestamp of the vision measurement in seconds.
     * @param visionMeasurementStdDevs Standard deviations of the vision pose measurement
     *     in the form [x, y, theta]ᵀ, with units in meters and radians.
     */
    @Override
    public void addVisionMeasurement(
        Pose2d visionRobotPoseMeters,
        double timestampSeconds,
        Matrix<N3, N1> visionMeasurementStdDevs
    ) {
        super.addVisionMeasurement(visionRobotPoseMeters, Utils.fpgaToCurrentTime(timestampSeconds), visionMeasurementStdDevs);
    }

    /**
     * Return the pose at a given timestamp, if the buffer is not empty.
     *
     * @param timestampSeconds The timestamp of the pose in seconds.
     * @return The pose at the given timestamp (or Optional.empty() if the buffer is empty).
     */
    @Override
    public Optional<Pose2d> samplePoseAt(double timestampSeconds) {
        return super.samplePoseAt(Utils.fpgaToCurrentTime(timestampSeconds));
    }

    public void ConfigureAutobuilder(){
    
    }

    public Rotation2d getAngleToScore() {
        if (RobotConstants.isRedAlliance.getAsBoolean()) {
            return new Rotation2d(Math.atan2(redHubPose.getY() - this.getState().Pose.getY(), redHubPose.getX() - this.getState().Pose.getX()));
        } else {
            return new Rotation2d(Math.atan2(blueHubPose.getY() - this.getState().Pose.getY(), blueHubPose.getX() - this.getState().Pose.getX()));
        }
    }

    public Rotation2d getAngleToScoreWhileMoving(double timeOfFlight) {
        ChassisSpeeds fieldRelativeSpeeds = ChassisSpeeds.fromRobotRelativeSpeeds(
            this.getState().Speeds, this.getState().Pose.getRotation());
        
        Translation2d robotTranslationOverTime = 
            new Translation2d(
                fieldRelativeSpeeds.vxMetersPerSecond * timeOfFlight, 
                fieldRelativeSpeeds.vyMetersPerSecond * timeOfFlight);

        if (RobotConstants.isRedAlliance.getAsBoolean()) {
            return new Rotation2d(
                Math.atan2(
                    redHubPose.getY() - robotTranslationOverTime.getY() - this.getState().Pose.getY(), 
                    redHubPose.getX() - robotTranslationOverTime.getX() - this.getState().Pose.getX()));
        } else {
            return new Rotation2d(
                Math.atan2(
                    blueHubPose.getY() - robotTranslationOverTime.getY() - this.getState().Pose.getY(), 
                    blueHubPose.getX() - robotTranslationOverTime.getX() - this.getState().Pose.getX()));
        }
    }

    public double getDistanceToHub() {
        if (appleTable.getEntry("tv").getDouble(0) != 1.0) {
            return -1;
        }

        if (RobotConstants.isRedAlliance.getAsBoolean()) {
            return getDistanceBetweenPoses(this.getState().Pose, redHubPose);
        } else {
            return getDistanceBetweenPoses(this.getState().Pose, blueHubPose);
        }
    }

    public double getDistanceToHubWhileMoving(double timeOfFlight) {
        if (appleTable.getEntry("tv").getDouble(0) != 1.0) {
            return -1;
        }

        ChassisSpeeds fieldRelativeSpeeds = ChassisSpeeds.fromRobotRelativeSpeeds(
            this.getState().Speeds, this.getState().Pose.getRotation());
        
        Translation2d robotTranslationOverTime = 
            new Translation2d(
                fieldRelativeSpeeds.vxMetersPerSecond * timeOfFlight, 
                fieldRelativeSpeeds.vyMetersPerSecond * timeOfFlight);

        if (RobotConstants.isRedAlliance.getAsBoolean()) {
            return getDistanceBetweenPoses(new Pose2d(redHubPose.getTranslation().minus(robotTranslationOverTime), new Rotation2d()), this.getState().Pose);
        } else {
            return getDistanceBetweenPoses(new Pose2d(blueHubPose.getTranslation().minus(robotTranslationOverTime), new Rotation2d()), this.getState().Pose);
        }
    }

    public static double getDistanceBetweenPoses(Pose2d pose1, Pose2d pose2) {
        return Math.sqrt(
                ((Math.abs(pose1.getX() - pose2.getX())) * (Math.abs(pose1.getX() - pose2.getX()))) +
                ((Math.abs(pose1.getY() - pose2.getY())) * (Math.abs(pose1.getY() - pose2.getY()))));
    }

    public void visionPeriodic(){
        setLLSettings();

        double timestamp = Timer.getTimestamp();
        visionProcessor.driveYawAngularVelocity.addSample(timestamp, this.getState().Speeds.omegaRadiansPerSecond);
        visionProcessor.measuredRobotRelativeChassisSpeeds.set(this.getState().Speeds);
        visionProcessor.robotPose.addSample(timestamp, this.getState().Pose);
        boolean gammaSeesTarget = appleTable.getEntry("tv").getDouble(0) == 1.0;
        if (gammaSeesTarget) { // does it see target?
            var megatag = LimelightHelpers.getBotPoseEstimate_wpiBlue("limelight-apple");
            var megatag2 = LimelightHelpers.getBotPoseEstimate_wpiBlue_MegaTag2("limelight-apple");
            if (megatag != null && megatag2 != null){
                visionProcessor.updateVision(
                    gammaSeesTarget,
                    FiducialObservation.fromLimelight(megatag.rawFiducials),
                    MegatagPoseEstimate.fromLimelight(megatag),
                    MegatagPoseEstimate.fromLimelight(megatag2),
                    "Vision/Gamma");
            }
        }
    }

    private void setLLSettings() {
        Rotation2d gyroAngle = this.getState().Pose.getRotation();
        double gyroAngularVelocity = Math.toDegrees(this.getState().Speeds.omegaRadiansPerSecond);
        try {
            LimelightHelpers.SetIMUMode("limelight-apple", 1);
            // LimelightHelpers.SetRobotOrientation(
            //         "limelight-apple",
            //         gyroAngle.getDegrees(), gyroAngularVelocity, 0, 0, 0, 0);

            Translation2d limelightToCenterOfTurret = 
                    new Translation2d(
                        0.0381, 
                        new Rotation2d(this.turretAngleSupplier.getAsDouble()));

            Translation2d limelightToRobot =
                limelightToCenterOfTurret.minus(new Translation2d(0, 0.1651));

            LimelightHelpers.setCameraPose_RobotSpace("limelight-apple",
            limelightToRobot.getY(),
            limelightToRobot.getX(),
            0.7747,
            0,
            0,
            Math.toDegrees(this.turretAngleSupplier.getAsDouble()));

            limelightDisplacedPose.set(new Pose2d(limelightToRobot, new Rotation2d(this.turretAngleSupplier.getAsDouble())));
        } catch (Exception e) {
           return;
        }
    }
}